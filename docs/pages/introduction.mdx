# Crawl4AI API Documentation

Welcome to the Crawl4AI API documentation! üöÄ

**Crawl4AI** is an AI-powered web crawling and scraping API built for developers. Extract clean, structured data from any website with LLM integration, intelligent parsing, and blazing-fast performance.

## What is Crawl4AI?

Crawl4AI transforms unstructured web content into clean, structured data ready for AI applications, data analysis, and automation. Whether you're building RAG pipelines, training models, or extracting insights, Crawl4AI handles the complexity of modern web scraping.

### Key Features

- üß† **AI-Powered Extraction** - LLM-optimized content parsing with semantic chunking
- ‚ö° **Blazing Fast** - Async processing with 10x faster performance
- üîå **Easy Integration** - RESTful API with SDKs for Python, JavaScript, and more
- üíæ **Smart Caching** - Intelligent caching reduces costs and improves speed
- üîê **Session Management** - Persistent browser sessions for authenticated crawling
- üí≥ **Flexible Pricing** - Pay-as-you-go with generous free tier

## Quick Start

Get started in 3 simple steps:

1. **Sign Up** - Create your account at [portal.crawl4ai.com](https://portal.crawl4ai.com)
2. **Get Your API Key** - Copy your API key from the dashboard
3. **Make Your First Request** - Start crawling!

```bash
curl -X POST https://api.crawl4ai.com/crawl/job \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "urls": ["https://example.com"],
    "extraction_config": {
      "type": "markdown"
    }
  }'
```

**Response:**

```json
{
  "job_id": "job_abc123",
  "status": "pending",
  "created_at": "2025-10-27T12:00:00Z"
}
```

[Read the full Quick Start guide ‚Üí](/quickstart)

## Use Cases

### RAG Pipelines

Extract and chunk content for Retrieval-Augmented Generation:

```json
{
  "urls": ["https://docs.example.com"],
  "extraction_config": {
    "type": "llm",
    "chunking": "semantic",
    "chunk_size": 1000
  }
}
```

### Data Analysis

Scrape structured data from multiple sources:

```json
{
  "urls": [
    "https://store.example.com/products",
    "https://competitor.com/pricing"
  ],
  "extraction_config": {
    "type": "json",
    "schema": {
      "products": "array"
    }
  }
}
```

### Automated Monitoring

Track changes on websites:

```json
{
  "urls": ["https://news.example.com"],
  "extraction_config": {
    "type": "markdown",
    "diff": true
  },
  "schedule": "daily"
}
```

## Pricing Plans

Choose the plan that fits your needs:

| Plan | Price | Rate Limit | Requests/Month |
|------|-------|------------|----------------|
| **Free** | $0 | 100/hour | 10,000 |
| **Crawler** | $39/month | 280/hour | 100,000 |
| **Spider** | $149/month | 1,388/hour | 1,000,000 |
| **Enterprise** | $499/month | 13,888/hour | 10,000,000 |

[View detailed pricing ‚Üí](https://portal.crawl4ai.com/pricing)

## SDK Examples

### Python

```python
import requests

API_KEY = "your_api_key_here"
response = requests.post(
    "https://api.crawl4ai.com/crawl/job",
    headers={"Authorization": f"Bearer {API_KEY}"},
    json={"urls": ["https://example.com"]}
)

job_id = response.json()["job_id"]
print(f"Job submitted: {job_id}")
```

### JavaScript

```javascript
const API_KEY = "your_api_key_here";

const response = await fetch("https://api.crawl4ai.com/crawl/job", {
  method: "POST",
  headers: {
    "Authorization": `Bearer ${API_KEY}`,
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    urls: ["https://example.com"]
  })
});

const { job_id } = await response.json();
console.log(`Job submitted: ${job_id}`);
```

## API Reference

Explore our complete API documentation:

- üìã [API Endpoints](/api) - Full reference with examples
- üîê [Authentication](/authentication) - API key setup and security
- üöÄ [Quick Start](/quickstart) - Step-by-step tutorial

## Resources

- üìö **[Full Documentation](https://docs.crawl4ai.com)** - In-depth guides and tutorials
- ‚≠ê **[GitHub](https://github.com/unclecode/crawl4ai)** - Open-source library (30k+ stars)
- üí¨ **[Discord Community](https://discord.gg/crawl4ai)** - Get help and share ideas
- üìß **[Support](mailto:support@crawl4ai.com)** - Email support for paid plans

## Getting Help

Need assistance?

1. **Check the docs** - Most questions are answered in our [comprehensive documentation](https://docs.crawl4ai.com)
2. **Join Discord** - Get help from our community at [discord.gg/crawl4ai](https://discord.gg/crawl4ai)
3. **Contact support** - Email us at support@crawl4ai.com (paid plans get priority)

## What's Next?

- ‚úÖ [Quick Start Guide](/quickstart) - Make your first API call
- ‚úÖ [Authentication](/authentication) - Set up your API keys
- ‚úÖ [API Reference](/api) - Explore all endpoints
- ‚úÖ [Upgrade Plan](https://portal.crawl4ai.com/pricing) - Increase your limits

---

Built with ‚ù§Ô∏è for developers. [Star us on GitHub](https://github.com/unclecode/crawl4ai) ‚≠ê
